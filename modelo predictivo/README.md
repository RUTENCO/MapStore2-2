# Sistema SAT - Pipeline de PredicciÃ³n de Deslizamientos

Este proyecto implementa un sistema completo para la predicciÃ³n de deslizamientos de tierra usando datos de lluvia del IDEAM, modelos de Machine Learning y generaciÃ³n de mapas de riesgo en formato GeoTIFF.

## ğŸ—ï¸ Arquitectura del Sistema

El sistema SAT estÃ¡ compuesto por 4 servicios principales ejecutÃ¡ndose en contenedores Docker:

### ğŸ“Š **Flujo de Datos**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸŒ§ï¸ Lluvia     â”‚â”€â”€â”€â–¶â”‚  ğŸ¤– Modelo      â”‚â”€â”€â”€â–¶â”‚  ğŸ—ºï¸ GeoTIFF    â”‚
â”‚  Processor      â”‚    â”‚  SAT            â”‚    â”‚  Exporter       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                       â”‚                       â”‚
        â–¼                       â–¼                       â–¼
ğŸ“„ lluvia_procesada      ğŸ“„ predicciones_sat    ğŸ“„ mapa_riesgo
   _latest.csv             _latest.gpkg           _latest.tif
```

### 1. **Lluvia Processor** (`lluvia_processor`)
- **FunciÃ³n**: Descarga y procesa datos de lluvia de las Ãºltimas 24h, 7 dÃ­as y 30 dÃ­as desde la API del IDEAM
- **Entrada**: Estaciones meteorolÃ³gicas (shapefile), token IDEAM
- **Salida**: Dataset con acumulados de lluvia por estaciÃ³n (`lluvia_procesada_latest.csv`)
- **TecnologÃ­a**: Python 3.12, GeoPandas, requests

### 2. **Modelo SAT** (`modelo_sat`)
- **FunciÃ³n**: Ejecuta modelo de Machine Learning para calcular probabilidades de deslizamiento
- **Entrada**: Datos de lluvia procesados
- **Salida**: Predicciones con probabilidades por estaciÃ³n (`predicciones_sat_latest.csv/gpkg`)
- **TecnologÃ­a**: Python 3.9.21, scikit-learn, Random Forest

### 3. **GeoTIFF Exporter** (`geotiff_exporter`)
- **FunciÃ³n**: Interpola probabilidades puntuales a superficie continua usando IDW
- **Entrada**: Predicciones del modelo, regiÃ³n andina (shapefile)
- **Salida**: Mapa de riesgo en formato GeoTIFF (`probabilidad_deslizamientos_latest.tif`)
- **TecnologÃ­a**: Python 3.12, Rasterio, GDAL, SciPy

### 4. **SAT Orchestrator** (`sat_orchestrator`)
- **FunciÃ³n**: Coordina la ejecuciÃ³n secuencial del pipeline y maneja la programaciÃ³n
- **Entrada**: ConfiguraciÃ³n de horarios (cron)
- **Salida**: Logs de ejecuciÃ³n y monitoreo del sistema
- **TecnologÃ­a**: Python 3.12, Docker API, Cron

## ğŸš€ InstalaciÃ³n y ConfiguraciÃ³n

### Prerrequisitos
- Docker Desktop instalado
- Docker Compose v2
- MÃ­nimo 4GB RAM disponible
- 2GB espacio en disco

### 1. Clonar y Preparar Archivos

```bash
# Navegar al directorio del proyecto
cd c:\Users\estiv\Downloads\modelo predictivo

# Verificar que estÃ¡n todos los archivos necesarios
dir
```

**Archivos requeridos:**
- `data/input/Region_andina_VivianaUrrea.shp` (+ .dbf, .prj, .shx)
- `data/input/estaciones_SAT_revis_nombres.shp` (+ .dbf, .prj, .shx)
- `docker-compose.yml` (en directorio raÃ­z)
- `.env` (en directorio raÃ­z)

### 2. Configurar Variables de Entorno

Editar el archivo `.env` segÃºn sea necesario:

```env
# Token de API IDEAM
IDEAM_TOKEN=VHmxDK45cRdGqCp2XBnesQVWQ

# ConfiguraciÃ³n de logging
LOG_LEVEL=INFO

# ConfiguraciÃ³n de interpolaciÃ³n
PIXEL_SIZE=0.01
BUFFER_DISTANCE=0.05

# Ejecutar pipeline al iniciar
RUN_ON_START=false

# URL del modelo pre-entrenado (opcional)
MODEL_URL=
```

### 3. ConstrucciÃ³n de Contenedores

```bash
# Construir todos los servicios
docker-compose build

# Verificar que las imÃ¡genes se crearon
docker images | findstr sat-pipeline
```

### 4. Preparar Datos de Entrada

Los archivos shapefile ya deben estar ubicados en `data/input/`. El script de inicializaciÃ³n se encargarÃ¡ de copiarlos automÃ¡ticamente a cada servicio.

**Estructura esperada:**
```
data/
â””â”€â”€ input/
    â”œâ”€â”€ Region_andina_VivianaUrrea.shp
    â”œâ”€â”€ Region_andina_VivianaUrrea.dbf
    â”œâ”€â”€ Region_andina_VivianaUrrea.prj
    â”œâ”€â”€ Region_andina_VivianaUrrea.shx
    â”œâ”€â”€ estaciones_SAT_revis_nombres.shp
    â”œâ”€â”€ estaciones_SAT_revis_nombres.dbf
    â”œâ”€â”€ estaciones_SAT_revis_nombres.prj
    â””â”€â”€ estaciones_SAT_revis_nombres.shx
```

## ğŸ¯ Uso del Sistema

### EjecuciÃ³n Manual Completa

```bash
# Ejecutar pipeline completo (lluvia â†’ modelo â†’ geotiff)
docker-compose up

# Ver logs en tiempo real
docker-compose logs -f
```

### EjecuciÃ³n de Servicios Individuales

```bash
# Solo procesamiento de lluvia
docker-compose run --rm lluvia-processor

# Solo modelo de predicciÃ³n
docker-compose run --rm modelo-sat

# Solo exportaciÃ³n GeoTIFF
docker-compose run --rm geotiff-exporter

# Solo orquestador (manual)
docker-compose run --rm sat-orchestrator python src/orchestrator.py --mode full
```

### Modo de Monitoreo Continuo

```bash
# Iniciar orquestador con programaciÃ³n automÃ¡tica
docker-compose up sat-orchestrator

# El sistema ejecutarÃ¡:
# - Pipeline completo diario a las 06:00
# - Pipeline parcial (modelo + geotiff) cada 6 horas
```

### Comandos de AdministraciÃ³n

```bash
# Ver estado de todos los servicios
docker-compose run --rm sat-orchestrator python src/orchestrator.py --mode status

# Ejecutar servicio especÃ­fico
docker-compose run --rm sat-orchestrator python src/orchestrator.py --service lluvia-processor

# Ver logs de un servicio especÃ­fico
docker-compose logs lluvia-processor

# Detener todos los servicios
docker-compose down

# Limpiar volÃºmenes (âš ï¸ elimina todos los datos)
docker-compose down -v
```

## ğŸ“Š Resultados y Archivos de Salida

### Estructura de Archivos Generados

```
data/
â”œâ”€â”€ input/                    # Archivos de entrada (shapefiles)
â”‚   â”œâ”€â”€ Region_andina_VivianaUrrea.shp
â”‚   â”œâ”€â”€ Region_andina_VivianaUrrea.dbf
â”‚   â”œâ”€â”€ Region_andina_VivianaUrrea.prj
â”‚   â”œâ”€â”€ Region_andina_VivianaUrrea.shx
â”‚   â”œâ”€â”€ estaciones_SAT_revis_nombres.shp
â”‚   â”œâ”€â”€ estaciones_SAT_revis_nombres.dbf
â”‚   â”œâ”€â”€ estaciones_SAT_revis_nombres.prj
â”‚   â””â”€â”€ estaciones_SAT_revis_nombres.shx
â””â”€â”€ output/                   # Archivos generados por el sistema
    â”œâ”€â”€ lluvia/
    â”‚   â”œâ”€â”€ lluvia_procesada_YYYYMMDD_HHMMSS.csv
    â”‚   â”œâ”€â”€ lluvia_procesada_latest.csv
    â”‚   â””â”€â”€ resumen_lluvia.json
    â”œâ”€â”€ modelo/
    â”‚   â”œâ”€â”€ predicciones_sat_YYYYMMDD_HHMMSS.csv
    â”‚   â”œâ”€â”€ predicciones_sat_latest.csv
    â”‚   â”œâ”€â”€ predicciones_sat_latest.gpkg
    â”‚   â””â”€â”€ estadisticas_modelo.json
    â””â”€â”€ geotiff/
        â”œâ”€â”€ probabilidad_deslizamientos_YYYYMMDD_HHMMSS.tif
        â”œâ”€â”€ probabilidad_deslizamientos_latest.tif
        â”œâ”€â”€ visualizacion_riesgo_latest.png
        â””â”€â”€ estadisticas_geotiff.json
logs/                         # Logs del sistema
â”œâ”€â”€ lluvia_processor.log
â”œâ”€â”€ modelo_sat.log
â”œâ”€â”€ geotiff_exporter.log
â”œâ”€â”€ orchestrator.log
â””â”€â”€ ejecucion_YYYYMMDD_HHMMSS.json
```

### InterpretaciÃ³n de Resultados

#### Niveles de Riesgo
- **ALTO** (â‰¥0.7): Rojo - Probabilidad alta de deslizamiento
- **MEDIO-ALTO** (0.5-0.69): Naranja - Riesgo considerable
- **MEDIO** (0.3-0.49): Amarillo - Riesgo moderado
- **BAJO-MEDIO** (0.1-0.29): Verde claro - Riesgo bajo-moderado
- **BAJO** (<0.1): Verde - Riesgo mÃ­nimo

#### Archivos Principales
- **`probabilidad_deslizamientos_latest.tif`**: Mapa raster final para anÃ¡lisis SIG
- **`predicciones_sat_latest.csv`**: Datos tabulares con probabilidades por estaciÃ³n
- **`visualizacion_riesgo_latest.png`**: Mapa visual del riesgo

## ğŸ”§ ConfiguraciÃ³n Avanzada

### Personalizar Horarios de EjecuciÃ³n

Editar `sat_orchestrator/crontab`:

```cron
# Ejecutar cada hora durante temporada de lluvias
0 * * * * /usr/local/bin/python /app/src/orchestrator.py --mode partial

# Ejecutar pipeline completo cada 12 horas
0 */12 * * * /usr/local/bin/python /app/src/orchestrator.py --mode full
```

### Configurar ResoluciÃ³n de InterpolaciÃ³n

En `.env`:

```env
# ResoluciÃ³n mÃ¡s alta (mÃ¡s detalle, mÃ¡s lento)
PIXEL_SIZE=0.005  # ~500m

# ResoluciÃ³n mÃ¡s baja (menos detalle, mÃ¡s rÃ¡pido)
PIXEL_SIZE=0.02   # ~2km
```

### AÃ±adir Modelo Pre-entrenado

```env
# URL de modelo pre-entrenado
MODEL_URL=https://ejemplo.com/modelo_sat_rf.pkl
```

### Configurar Logging Detallado

```env
# Nivel de logging mÃ¡s detallado
LOG_LEVEL=DEBUG
```

## ğŸ› ResoluciÃ³n de Problemas

### Problemas Comunes

#### 1. Error "Archivos shapefile no encontrados"
```bash
# Verificar que los archivos estÃ¡n en el lugar correcto
dir lluvia_processor\data\*.shp
dir modelo_sat\data\*.shp
dir geotiff_exporter\data\*.shp
```

#### 2. Error de conexiÃ³n con API IDEAM
```bash
# Verificar token en .env
echo %IDEAM_TOKEN%

# Probar conexiÃ³n manual
curl "https://dhime.ideam.gov.co/atenea/?token=VHmxDK45cRdGqCp2XBnesQVWQ&format=json"
```

#### 3. Contenedor se detiene inmediatamente
```bash
# Ver logs detallados
docker-compose logs lluvia-processor

# Ejecutar en modo interactivo para debugging
docker-compose run --rm lluvia-processor bash
```

#### 4. Problemas de memoria/rendimiento
```bash
# Verificar recursos disponibles
docker system df
docker stats

# Ajustar lÃ­mites en docker-compose.yml
```

### Logs y Debugging

```bash
# Ver todos los logs
docker-compose logs

# Seguir logs en tiempo real
docker-compose logs -f --tail=100

# Logs de un servicio especÃ­fico
docker-compose logs lluvia-processor

# Entrar a un contenedor para debugging
docker-compose exec lluvia-processor bash
```

### Monitoreo del Sistema

```bash
# Estado de contenedores
docker-compose ps

# Uso de recursos
docker stats $(docker-compose ps -q)

# Espacio en disco
docker system df

# Limpiar recursos no utilizados
docker system prune
```

## ğŸ“ˆ Monitoreo y Mantenimiento

### VerificaciÃ³n de Salud del Sistema

```bash
# Script de verificaciÃ³n diaria
docker-compose run --rm sat-orchestrator python src/orchestrator.py --mode status

# Verificar archivos de salida recientes
dir data\output\geotiff\*latest*

# Verificar logs por errores
findstr /i "error" logs\*.log
```

### Respaldo de Datos

```bash
# Respaldar datos importantes
xcopy data\output backup\data_YYYYMMDD /E /I

# Respaldar logs
xcopy logs backup\logs_YYYYMMDD /E /I
```

### Limpieza AutomÃ¡tica

Crear script `cleanup.bat`:

```batch
@echo off
echo Limpiando archivos antiguos...

# Eliminar archivos de mÃ¡s de 30 dÃ­as
forfiles /p data\output /r /m *.* /d -30 /c "cmd /c del @path"

# Limpiar logs antiguos
forfiles /p logs /r /m *.log /d -7 /c "cmd /c del @path"

echo Limpieza completada
```

## ğŸ”’ Consideraciones de Seguridad

1. **Token IDEAM**: Mantener el token seguro y rotarlo periÃ³dicamente
2. **Acceso a archivos**: Configurar permisos apropiados en directorios de datos
3. **Actualizaciones**: Mantener imÃ¡genes Docker actualizadas
4. **Monitoreo**: Configurar alertas para fallos del sistema

## ğŸ“ Soporte y Contacto

Para problemas tÃ©cnicos o mejoras al sistema:

1. Revisar logs del sistema
2. Consultar esta documentaciÃ³n
3. Verificar configuraciÃ³n de Docker y variables de entorno
4. Contactar al equipo de desarrollo con logs especÃ­ficos

---

**Sistema SAT - Pipeline de PredicciÃ³n de Deslizamientos**  
*VersiÃ³n Dockerizada para ProducciÃ³n*
